---
title: LLMs as Classifiers - Guide
---

## Table of Contents
- [Objective](#objective)
- [Dataset Preparation](#dataset-preparation)
  - [Classification Data Format](#classification-data-format)
- [Finetuning Preparation](#finetuning-preparation)
  - [Create Model Service](#create-model-service)
  - [Uploading Datasets](#uploading-datasets)
- [Model Finetuning](#model-finetuning)
  - [Selecting Base Model](#selecting-base-model)
  - [Training Parameter Configuration](#training-parameter-configuration)
    - [Selecting Classification Option](#selecting-classification-option)
- [Model Monitoring & Evaluation](#model-monitoring--evaluation)
  - [Using Test Datasets](#using-test-datasets)
  - [Evaluation Metric Interpretation](#evaluation-metric-interpretation)
- [Deployment](#deployment)
  - [Finetuned Model Deployment](#finetuned-model-deployment)
  - [Parameter Recalibration](#parameter-recalibration)
- [Best Practices](#best-practices)

## 1. Objective

This guide provides step-by-step instructions on finetuning a model for **Text Classification** tasks on Emissary using our novel classification approach. In this approach, we add a classification head on top of the base LLMs that returns probabilities for a given set of labels. We recommend using **Llama3.1-8B-instruct** for this task.

## 2. Dataset Preparation

Prepare your dataset in the appropriate format for the classification task.

## Classification Data Format

**Each entry should contain:**

- **Prompt**: The input text for classification.
- **Completion**: A binary value (0 or 1) indicating the classification output. Only `1` or `0` should be used to denote the classification result.


### For Binary Classification Data (Single Label)

**JSONL Format**

```json
{
  "prompt": "This is a sample text for binary classification",
  "completion": 1
}
```

**CSV Format**
```csv
input,expected_output
"This is a sample text for binary classification",1
"This is another sample text for binary classification",0
```

### For Multi-Class/Multi-Label Binary Classification
In cases where multiple labels are evaluated independently, the completion should be a dictionary where each label is mapped to a binary value (0 or 1) to indicate its relevance.

**JSONL Format**

```json
{
  "prompt": "This is a sample text for classification",
  "completion": {
    "Label_1": 1,
    "Label_2": 0,
    "Label_3": 1,
    "Label_N": 0
  }
}

```

**CSV Format**
```csv
input,expected_output
"This is a sample text for binary classification", "{"Label_1": 1, "Label_2": 0, "Label_3": 1, "Label_N": 0}"
```

## 3. Finetuning Preparation

Please refer to the in-depth guide on Finetuning on Emissary here - [Quickstart Guide](../finetuning/quickstart)

### Create Model Service
Navigate to **Dashboard** arriving at **Model Services**, the default page on the Emissary platform.

1. Click **+ NEW SERVICE** in the dashboard.  
   <Card>
        <img src="/images/guides/project_create1.png" />
    </Card> 
2. In the pop-up, enter a new model service name, and click **CREATE**.  
   <Card>
        <img src="/images/guides/project_create2.png" />
    </Card> 

### Uploading Datasets

A tile is created for your task. Click **Manage** to enter the task workspace.  
    <Card>
        <img src="/images/guides/project_manage1.png" />
    </Card>

1. Click **MANAGE** in the **Datasets Available** tile.  
    <Card>
        <img src="/images/guides/project_manage2.png" />
    </Card>
2. Click on **+ UPLOAD DATASET** and select training and test datasets.  
   <Card>
        <img src="/images/finetuning/upload_dataset.png" />
    </Card>

3. Name datasets clearly to distinguish between training and test data (e.g., <span style={{ color: 'green' }}>train_classification_data.csv</span>, <span style={{ color: 'green' }}>test_classification_data.csv</span>).

## 4. Model Finetuning
Now, go back one panel by clicking **OVERVIEW** and then click **MANAGE** in the **Training Jobs** tile.
<Card> <img src="/images/guides/project_manage3.png" /> </Card>

Here, weâ€™ll kick off finetuning. The shortest path to finetuning a model is by clicking **+ NEW TRAINING JOB**, naming the output model, picking a backbone (**base model**), selecting the training dataset (you must have uploaded it in the step before), and finally hitting **START NEW TRAINING JOB**.

### Selecting Classification Option
When creating a new training job, you need to specify that you are performing a classification task to utilize the novel classification approach.

In the Training Job Creation page, locate the Task Type option.
Select **Classification** from the given options.

This selection ensures that a **classification head** is added on top of the base LLM, enabling the model to return **probabilities** for the specified labels.

<Card> <img src="/images/guides/train_classification.png" /> </Card>

A custom function that calculates a matching score for the given expected and predicted outputs, based on how well the binary expected labels match the predicted probabilities has been provided.
Uncomment the suitable classification metric function to use it.

<Card> <img src="/images/guides/classification_metric.png" /> </Card>
### Training Parameter Configuration
Please refer to the in-depth guide on configuring training parameters here - [Finetuning Parameter Guide](../finetuning/parameters).


## 5. Model Monitoring & Evaluation

### Using Test Datasets

Including a test dataset allows you to evaluate the model's performance during training.

- **Per Epoch Evaluation**: The platform evaluates the model at each epoch using the test dataset.
- **Metrics and Outputs**: View evaluation metrics and generated outputs for test samples.
- Post completion of training, check scores in **Training Job --> Artifacts**.
    <br></br>For the **LLM model**, expect the following:  

<Card> <img src="/images/guides/evaluate_classification.png" /> </Card>

## 6. Deployment
Refer to the in-depth walkthrough on deploying a model on Emissary here - [Deployment Guide](../finetuning/deployments).

Deploying your models allows you to serve them and integrate them into your applications.

### Finetuned Model Deployment
1. Navigate to the **Training Jobs Page**. From the list of finetuning jobs, select the one you want to deploy.
<Card> <img src="/images/guides/deployment_fine_tuned.png" /> </Card>
2. Go to the **ARTIFACTS** tab.
<Card> <img src="/images/guides/artifacts1.png" /> </Card>
3. Select a **Checkpoint** to Deploy.
<Card> <img src="/images/guides/checkpoint_evaluate.png" /> </Card>
4. Go to **Deployments** to check the status of you deployed model
<Card> <img src="/images/guides/deployment.png" /> </Card>
5. Once the model is deployed (as shown in the status), go to the testing tab.
<Card> <img src="/images/guides/deployment_status.png" /> </Card>
6. Test your samples in the the input box.
<Card> <img src="/images/guides/testing_tab.png" /> </Card>

## 7. Best Practices
- **Start Small**: Begin with a smaller dataset to validate your setup.
- **Monitor Training**: Keep an eye on training logs and metrics.
- **Iterative Testing**: Use the test dataset to iteratively improve your model.
- **Data Format**: Use the recommended data formats for your chosen model to ensure compatibility and optimal performance.
